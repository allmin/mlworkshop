{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Classification using Deep Learning\n",
    "Author: Allmin Susaiyah\n",
    "\n",
    "Name of student:\n",
    "\n",
    "In this notebook, image classification using deep learning is covered. shift + Enter will excecute each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('result_images'):\n",
    "    os.makedirs('result_images')\n",
    "if os.path.exists('input_images'):\n",
    "    shutil.rmtree('input_images')\n",
    "os.makedirs('input_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aquiring dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47292it [02:10, 318.47it/s]"
     ]
    }
   ],
   "source": [
    "#Acquiring data and assigning them into folders\n",
    "Total_Images = 70000\n",
    "if len(glob(\"input_images/*/*/*.png\")) < Total_Images:\n",
    "    print(\"aquiring dataset\")\n",
    "    (x_train, y_train), (x_val, y_val) = mnist.load_data()\n",
    "    \n",
    "    for ind,(im,y) in tqdm(enumerate(zip(x_train, y_train))):\n",
    "        IM = Image.fromarray(im)\n",
    "        op_dir = \"input_images/train/{}/\".format(y)\n",
    "        if not os.path.exists(op_dir):\n",
    "            os.makedirs(op_dir)\n",
    "        IM.save(op_dir + \"image_{:06d}.png\".format(ind))\n",
    "\n",
    "\n",
    "    for ind,(im,y) in tqdm(enumerate(zip(x_val, y_val))):\n",
    "        IM = Image.fromarray(im)\n",
    "        op_dir = \"input_images/validation/{}/\".format(y)\n",
    "        if not os.path.exists(op_dir):\n",
    "            os.makedirs(op_dir)\n",
    "        IM.save(op_dir + \"image_{:06d}.png\".format(ind))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "# loading images\n",
    "list_all_images = glob(\"input_images/*/*/*.*\")\n",
    "x_train = []; y_train = []; x_val = []; y_val = []\n",
    "for ind,image_path in tqdm(enumerate(list_all_images)):\n",
    "    mode,label,file_name = image_path.split(os.path.sep)[-3:]\n",
    "    label = int(label)\n",
    "    \n",
    "    im = np.array(Image.open(image_path))\n",
    "    if mode == 'train':\n",
    "        x_train.append(im)\n",
    "        y_train.append(label)\n",
    "    elif mode == 'validation':\n",
    "        x_val.append(im)\n",
    "        y_val.append(label)\n",
    "        \n",
    "x_train = np.array(x_train)\n",
    "x_val = np.array(x_val)\n",
    "# (x_train, y_train), (x_val, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_train))\n",
    "# [img_rows, img_cols] = x_train.shape[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# requests.packages.urllib3.disable_warnings()\n",
    "# import ssl\n",
    "# try:\n",
    "#    _create_unverified_https_context = ssl._create_unverified_context\n",
    "# except AttributeError:\n",
    "#    # Legacy Python that doesn't verify HTTPS certificates by default\n",
    "#    pass\n",
    "# else:\n",
    "#    # Handle target environment that doesn't support HTTPS verification\n",
    "#    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_val = x_val.reshape(x_val.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_val = x_val.reshape(x_val.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_train /= 255\n",
    "x_val /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_val.shape[0], 'test samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "# my_callbacks = [keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_int = np.argmax(y_pred,axis=1)\n",
    "y_val_int = np.argmax(y_val,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying test images with predicted label\n",
    "for ind,(im,ya,yp) in enumerate(zip(x_val,y_val_int,y_pred_int)):\n",
    "    plt.imshow(im[:,:,0],cmap='gray')\n",
    "    plt.title(\"actual:{}, predicted:{}\".format(ya,yp))\n",
    "    plt.savefig(\"result_images/image_{:06d}_actual_{}_predicted_{}\".format(ind,ya,yp))\n",
    "    plt.show()\n",
    "    if ind == 100:\n",
    "        break\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
